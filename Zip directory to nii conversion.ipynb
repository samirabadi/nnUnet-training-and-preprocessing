{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987388c-a8d9-4704-b963-8339129cf801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import JupyterNotebooksLib as slicernb\n",
    "import slicer\n",
    "import os \n",
    "from DICOMLib import DICOMUtils\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set image viewer size to 50% screen size\n",
    "# slicernb.AppWindow.setWindowSize(scale=0.5)\n",
    "# slicernb.AppWindow.setContents(\"viewers\")\n",
    "\n",
    "# Clear scene\n",
    "slicer.mrmlScene.Clear(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40206a5-80d4-4964-97eb-5ed2bfa81407",
   "metadata": {},
   "source": [
    "# Unzip and organize files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c786768-bcab-4ae5-af6b-2cc0087449a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input folder \n",
    "input_folder = \"C:\\\\Users\\\\Sepehr\\\\3dsegmentationProjects\\\\nn-unet-organize-dataset-for-training\\\\Segmentation database\"\n",
    "intermediary_folder = \"./temp_unzip\"\n",
    "\n",
    "if  not os.path.exists(intermediary_folder):\n",
    "    os.mkdir(intermediary_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706e0ab-c6a7-4c20-a9cc-ce71b6f99c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for zip_file in os.listdir(input_folder):\n",
    "#     if \"(\" in zip_file or \")\" in zip_file:\n",
    "#         continue;\n",
    "#     zip_path = f\"{input_folder}/{zip_file}\"\n",
    "#     Case_id = zip_file.split(\"_\")[0]\n",
    "\n",
    "#     if \"_segmented_structures\" in zip_file: \n",
    "#         out_path = f\"{intermediary_folder}/{Case_id}_segmentations\"\n",
    "#     else:\n",
    "#         out_path = f\"{intermediary_folder}/{Case_id}_volumes\"\n",
    "        \n",
    "#     with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#                     zip_ref.extractall(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf8913f-d980-429b-8a23-829200bcc547",
   "metadata": {},
   "source": [
    "# organize file names throw out unuasable cases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4fa809-bf6c-4bf8-ac05-3b56198ddd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cases = [] \n",
    "\n",
    "\n",
    "volumes_paths = list(natsorted(glob(os.path.join(intermediary_folder,  \"*\"+ f\"_volumes\"))))\n",
    "\n",
    "for vol in volumes_paths: \n",
    "\n",
    "    seg_path = vol.replace (\"_volumes\",\"_segmentations\")\n",
    "\n",
    "    if (os.path.exists(seg_path)):\n",
    "        input_cases.append ({\"vol\":vol,\"seg\":seg_path})\n",
    "    else:\n",
    "        print (\"cannot find matching segmentation case will be skipped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f67a9d0-ddf1-4041-b0f4-b487b01c6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cases[0][\"vol\"].split(\"\\\\\")[-1].split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf0bcb-d3a1-4de7-8f10-4b3d2b1f81c5",
   "metadata": {},
   "source": [
    "# using slicer to convert to nii\n",
    "\n",
    "### will need to alter segmentation nodes to reflect changes in classes you are trying to segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ece8a6-f3bd-4d53-8a78-921dc34cfa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_path = \"./nii_ds_1\"\n",
    "nii_path_volumes = f\"{nii_path}/Volumes\"\n",
    "nii_path_segmentations = f\"{nii_path}/Masks\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(nii_path)\n",
    "    os.mkdir(nii_path_volumes)\n",
    "    os.mkdir(nii_path_segmentations)\n",
    "except:\n",
    "    print (\"these directories already exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859f038-f7c1-44e9-90f9-59d196e6f73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_class_from_file (file): \n",
    "    if \"tooth_\" in file: \n",
    "        #print (file.split(\"tooth_\")[1].split(\"_\")[0])\n",
    "        return file.split(\"tooth_\")[1].split(\"_\")[0]\n",
    "\n",
    "    else: \n",
    "        # CaseId = file.split(\"_\") [-1].split(\".)\n",
    "        # #print (file.split(f\"{CaseId}_\")[-1].split(\"_\")[0])\n",
    "        return file.split(\"_\") [-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92002c8d-22ff-4871-951d-33edd9f05852",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_class_from_file (\"304846_canal.stl\")\n",
    "#\"304846_canal.stl\".split(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7874e6-4db8-4e46-87e9-fac21d7237c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_nnunet_lable_structure (lable_dict,referenceVolumeNode):\n",
    "\n",
    "    all_segment_np = [] \n",
    "    for lable, node in lable_dict.items():\n",
    "        name = node.GetName()\n",
    "    \n",
    "        segmentationLblmap  = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLLabelMapVolumeNode\")\n",
    "        segmentationLblmap.SetName(name+\"_lablemap\")\n",
    "        slicer.modules.segmentations.logic().ExportVisibleSegmentsToLabelmapNode(node, segmentationLblmap, referenceVolumeNode)\n",
    "        mask = slicer.util.arrayFromVolume(segmentationLblmap)\n",
    "        mask[mask > 0] = lable\n",
    "    \n",
    "        all_segment_np.append(mask.copy())\n",
    "\n",
    "\n",
    "\n",
    "    final_out = all_segment_np[0] \n",
    "    for i in range (1,6):\n",
    "        indices  = np.where (final_out <1)\n",
    "        final_out [indices] = all_segment_np[i][indices]\n",
    "\n",
    "    segmentationLblmap  = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLLabelMapVolumeNode\")\n",
    "    slicer.modules.segmentations.logic().ExportVisibleSegmentsToLabelmapNode(lable_dict[5], segmentationLblmap, referenceVolumeNode)\n",
    "    \n",
    "    slicer.util.updateVolumeFromArray(segmentationLblmap, final_out)\n",
    "\n",
    "    return segmentationLblmap\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8fd93-f235-4aac-b699-dcbe2d1ae5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxillary_teeth_lables = [\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\"]\n",
    "mandibular_teeth_lables = [\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\"]\n",
    "\n",
    "def convert_single_case_to_nii (dicom_series_path,segmentation_path):\n",
    "\n",
    "    '''\n",
    "    simply loading dicoms into a fresh scene \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # # Clear scene\n",
    "    slicer.mrmlScene.Clear(False)\n",
    "\n",
    "    print(dicom_series_path)\n",
    "    print(segmentation_path)\n",
    "    \n",
    "    ##load dicom \n",
    "    loadedNodeIDs = []\n",
    "    with DICOMUtils.TemporaryDICOMDatabase() as db:\n",
    "        DICOMUtils.importDicom(os.path.abspath(dicom_series_path), db)\n",
    "        patientUIDs = db.patients()\n",
    "    \n",
    "        print (patientUIDs)\n",
    "        for patientUID in patientUIDs:\n",
    "            loadedNodeIDs.extend(DICOMUtils.loadPatientByUID(patientUID))\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    loading the segmentations into appropriate substructuresz \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    ## creating segmentation nodes\n",
    "    maxillaNode = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLSegmentationNode\")\n",
    "    maxillaNode.CreateDefaultDisplayNodes()\n",
    "    maxillaNode.SetName (\"maxillaNode\")\n",
    "    \n",
    "    mandibleNode = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLSegmentationNode\")\n",
    "    mandibleNode.CreateDefaultDisplayNodes()\n",
    "    mandibleNode.SetName (\"mandibleNode\")\n",
    "    \n",
    "    maxillaryTeethNode = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLSegmentationNode\")\n",
    "    maxillaryTeethNode.CreateDefaultDisplayNodes()\n",
    "    maxillaryTeethNode.SetName (\"maxillaryTeethNode\")\n",
    "    \n",
    "    mandibularTeethNode = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLSegmentationNode\")\n",
    "    mandibularTeethNode.CreateDefaultDisplayNodes()\n",
    "    mandibularTeethNode.SetName (\"mandibularTeethNode\")\n",
    "    \n",
    "    canalNode = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLSegmentationNode\")\n",
    "    canalNode.CreateDefaultDisplayNodes()\n",
    "    canalNode.SetName (\"canalNode\")\n",
    "    \n",
    "    sinusNode = slicer.mrmlScene.AddNewNodeByClass(\"vtkMRMLSegmentationNode\")\n",
    "    sinusNode.CreateDefaultDisplayNodes()\n",
    "    sinusNode.SetName (\"sinusNode\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## importing stls and binding them to the appropriate node \n",
    "    nodes = []\n",
    "    node_names = []\n",
    "    for seg in os.listdir(segmentation_path):\n",
    "        if (\".stl\" in seg):\n",
    "            mesh_path = f\"{segmentation_path}/{seg}\"\n",
    "    \n",
    "            class_name = get_model_class_from_file(seg)\n",
    "            # print (seg)\n",
    "    \n",
    "            if class_name in maxillary_teeth_lables:\n",
    "                slicer.modules.segmentations.logic().ImportModelToSegmentationNode(slicer.util.loadModel(mesh_path), maxillaryTeethNode)\n",
    "            elif class_name in mandibular_teeth_lables:\n",
    "                slicer.modules.segmentations.logic().ImportModelToSegmentationNode(slicer.util.loadModel(mesh_path), mandibularTeethNode)\n",
    "            elif class_name == \"maxilla\":\n",
    "                slicer.modules.segmentations.logic().ImportModelToSegmentationNode(slicer.util.loadModel(mesh_path), maxillaNode)\n",
    "            elif class_name == \"mandible\":\n",
    "                slicer.modules.segmentations.logic().ImportModelToSegmentationNode(slicer.util.loadModel(mesh_path), mandibleNode)\n",
    "            elif class_name == \"sinus\":\n",
    "                slicer.modules.segmentations.logic().ImportModelToSegmentationNode(slicer.util.loadModel(mesh_path), sinusNode)\n",
    "            elif class_name == \"canal\":\n",
    "                slicer.modules.segmentations.logic().ImportModelToSegmentationNode(slicer.util.loadModel(mesh_path), canalNode)\n",
    "\n",
    "\n",
    "    referenceVolumeNode = slicer.mrmlScene.GetNodeByID(\"vtkMRMLScalarVolumeNode1\")\n",
    "    lable_dict = {1:sinusNode,2:canalNode , 3:mandibleNode,4:maxillaNode, 5:maxillaryTeethNode,6:mandibularTeethNode}\n",
    "\n",
    "    segmentation_lable_map = convert_to_nnunet_lable_structure(lable_dict,referenceVolumeNode)\n",
    "\n",
    "    caseID = dicom_series_path.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    volume_save_path = f\"{nii_path_volumes}/{caseID}_volume.nii.gz\"\n",
    "    seg_save_path =  f\"{nii_path_segmentations}/{caseID}_seg.nii.gz\"\n",
    "\n",
    "    slicer.util.exportNode(referenceVolumeNode, volume_save_path , {\"useCompression\": 0})\n",
    "    slicer.util.exportNode(segmentation_lable_map, seg_save_path , {\"useCompression\": 0})\n",
    "\n",
    "    print (\"one case sucessfully converted\")\n",
    "     \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4afd5c-a0cf-41b2-98e8-f497f8a7e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_nii_convert (in_case_files):\n",
    "\n",
    "    for case in tqdm(in_case_files):\n",
    "        try:\n",
    "            convert_single_case_to_nii (case[\"vol\"],case[\"seg\"])\n",
    "        except:\n",
    "            print (f\"somthing is wrong with case {case} probably a missing segmentation\")\n",
    "    print (\"done converting all cases to nii\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78215f33-47f9-4dab-aa75-45268bbb3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_nii_convert (input_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd95b1-d062-4235-992e-4048effdb08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_single_case_to_nii (input_cases[0][\"vol\"],input_cases[0][\"seg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ecaf2-80a2-46b7-98ed-1b1936084477",
   "metadata": {},
   "source": [
    "# building nnunet_dataset from nii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3753e3-750a-4644-b07a-c3d035c7b32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making dataset Folder \n",
    "\n",
    "dataset_id = 125\n",
    "dataset_name = \"Max-Mand-Sinus-Teeth\" \n",
    "Dataset_folder_name = f\"Dataset{dataset_id}_{dataset_name}\"\n",
    "\n",
    "if (not os.path.exists(f\"./nnUNet_raw/{Dataset_folder_name}\")):\n",
    "    os.mkdir(f\"./nnUNet_raw/{Dataset_folder_name}\")\n",
    "\n",
    "train_input_dir = f\"./nnUNet_raw/{Dataset_folder_name}/imagesTr\"\n",
    "train_lable_dir = f\"./nnUNet_raw/{Dataset_folder_name}/labelsTr\"\n",
    "\n",
    "if not os.path.exists(train_input_dir):\n",
    "    os.mkdir(train_input_dir)\n",
    "if not os.path.exists(train_lable_dir):\n",
    "    os.mkdir(train_lable_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3865e6d-e787-4654-86f9-f81bf8253133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "volume_list = os.listdir(nii_path_volumes)\n",
    "seg_list = os.listdir(nii_path_segmentations)\n",
    "# print (volume_list)\n",
    "\n",
    "for volume in volume_list:\n",
    "    volume_old_path = f\"{nii_path_volumes}/{volume}\"\n",
    "    volume_nnunet_name = volume.replace (\"_volume.nii.gz\",\"_0000.nii.gz\")\n",
    "    volume_new_path = f\"{train_input_dir}/{volume_nnunet_name}\"\n",
    "\n",
    "    #print (volume_nnunet_name)\n",
    "    shutil.copy(volume_old_path, volume_new_path)\n",
    "\n",
    "\n",
    "for segmentation in seg_list:\n",
    "    segmentation_old_path = f\"{nii_path_segmentations}/{segmentation}\"\n",
    "    segmentation_nnunet_name = segmentation.replace (\"_seg.nii.gz\",\".nii.gz\")\n",
    "    segmentation_new_path = f\"{train_lable_dir}/{segmentation_nnunet_name}\"\n",
    "\n",
    "    #print (segmentation_nnunet_name)\n",
    "    shutil.copy(segmentation_old_path, segmentation_new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9adf213-d7fe-4681-a374-8a67acab6bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating Dataset Json \n",
    "import json \n",
    "\n",
    "dataset_metadata = {\n",
    " \"channel_names\": {  # formerly modalities\n",
    "   \"0\": \"CT\", \n",
    " }, \n",
    " \"labels\": {  # THIS IS DIFFERENT NOW!\n",
    "   \"background\": 0,\n",
    "   \"sinus\": 1,\n",
    "   \"canal\": 2,\n",
    "   \"mandible\": 3,\n",
    "   \"maxilla\":4,\n",
    "   \"maxillary_teeth\":5,\n",
    "   \"mandibular_teeth\":6  \n",
    " }, \n",
    " \"numTraining\": len(volume_list), \n",
    " \"file_ending\": \".nii.gz\",\n",
    " \"overwrite_image_reader_writer\": \"SimpleITKIO\"  # optional! If not provided nnU-Net will automatically determine the ReaderWriter\n",
    " \n",
    "}\n",
    "\n",
    "json_data = json.dumps(dataset_metadata)\n",
    "\n",
    "with open(f\"./nnUNet_raw/{Dataset_folder_name}/dataset.json\", \"w\") as outfile:\n",
    "    outfile.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266cc80-479a-4baa-8252-1e9d00ef5d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Slicer 5.6",
   "language": "python",
   "name": "slicer-5.6"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
